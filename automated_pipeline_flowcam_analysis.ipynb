{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated pipeline for the extraction and analysis of flowcam data with special attention paid to the detection and characterization of *Phaeocystis antarctica*. \n",
    "\n",
    "## January 2018\n",
    "## McMurdo Station, Antarctica\n",
    "\n",
    "### Harriet Alexander"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy import ndimage as ndi\n",
    "import glob\n",
    "from itertools import compress\n",
    "import pandas as pd\n",
    "import pickle as cpk\n",
    "\n",
    "from skimage import measure\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import feature\n",
    "from skimage.filters import roberts, sobel, scharr, prewitt\n",
    "from skimage import segmentation \n",
    "from skimage import data\n",
    "from skimage import measure\n",
    "from skimage import filters\n",
    "from skimage import morphology\n",
    "from skimage import restoration\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage import util\n",
    "from skimage import draw\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cutting individual tifs from mother image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_bw_background(I, thresh=None):\n",
    "    '''\n",
    "    rgb_to_bw_background: converts image to bw based on chosen threshold; automatically use yen. \n",
    "\n",
    "    I = image handle (intialized with scikit image package using io.imread)\n",
    "    thresh = threhold value (float)\n",
    "    '''\n",
    "    Ig = color.rgb2gray(I)\n",
    "    if thresh is None:\n",
    "        thresh = filters.threshold_yen(Ig)\n",
    "    Ibw = Ig > thresh\n",
    "    Ibw = Ibw.astype(int)\n",
    "    \n",
    "    return(Ibw)\n",
    "\n",
    "def cutImage(motherTif, outdir, pad=10,):\n",
    "    '''\n",
    "    cutImage: takes in FlowCam collage and cuts out individual\n",
    "    images from the background and saves them as tifs\n",
    "\n",
    "    motherTif = filename of collage tif file (str)\n",
    "    pad = size of padding to put around the image (int)\n",
    "    '''\n",
    "    # read in image\n",
    "    motherimg = io.imread(motherTif)\n",
    "    \n",
    "    # get bw verion of image\n",
    "    imgbw = rgb_to_bw_background(motherimg, 0)\n",
    "    \n",
    "    # pad with black\n",
    "    imgbw = np.pad(imgbw, [pad,pad], 'constant', constant_values=0)\n",
    "\n",
    "    # label regions\n",
    "    imlab=measure.label(imgbw)\n",
    "    \n",
    "    # get boudning box\n",
    "    rp = measure.regionprops(imlab)\n",
    "    \n",
    "    \n",
    "    # get name for tif file\n",
    "    mother_out = motherTif.split('/')[-1].split('.')[0]\n",
    "    \n",
    "    # make directory if doesn't exist\n",
    "    if not os.path.exists(outdir):\n",
    "        os.makedirs(outdir)\n",
    "    \n",
    "    # cut images\n",
    "    for i,r in enumerate(rp):\n",
    "        bbox =r['bbox']\n",
    "        # bbox = (min_row, min_col, max_row, max_col)\n",
    "        x1 = bbox[0]-pad\n",
    "        x2 = bbox[2]-pad\n",
    "        y1 = bbox[1]-pad\n",
    "        y2 = bbox[3]-pad\n",
    "        outimg = motherimg[x1:x2, y1:y2, :]\n",
    "        np.shape(outimg)\n",
    "        io.imsave(outdir + '/' + mother_out+'_' + str(i).zfill(4)+'.tif', outimg)\n",
    "        \n",
    "def batch_cut_images(directory, outdirectory, ftype = '*tif', test=False):\n",
    "    '''\n",
    "    batch_cut_images: loops through a directory and runs cutImage on \n",
    "    all *tif files in the directory\n",
    "\n",
    "    directory = name of directory (str)\n",
    "    outdirectory = name of the directory to save the new imgages to (str)\n",
    "    ftype = file type to search for (str)\n",
    "    '''\n",
    "    for ifile in glob.glob('/'.join([directory, ftype])):\n",
    "        dirName = ifile.split('/')[-2] \n",
    "        name = ifile.split('/')[-1] \n",
    "        \n",
    "        # skip binary and calibration files generated by the flow cam\n",
    "        if name.endswith('bin.tif'):\n",
    "            pass\n",
    "        elif name.startswith('cal_image'):\n",
    "            pass\n",
    "        else:\n",
    "            if test ==True:\n",
    "                print(directory+name)\n",
    "            else:   \n",
    "                cutImage(directory + name, '/'.join([outdirectory, dirName]))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop over raw data files in `data/rawdata/`, generate new individual tif files, and save to `data/processed-data/individual-tifs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/rawdata/20180129-IceEdge-sample0127-0m-500ml/\n",
      "data/rawdata/20180129-IceEdge-sample0127-10m-200ml/\n",
      "data/rawdata/20180129-IceEdge-sample0127-10m-50ml/\n",
      "data/rawdata/20180129-IceEdge-sample0127-nettow-20ml/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/skimage/io/_io.py:132: UserWarning: data/processed-data/individual-tifs//20180129-IceEdge-sample0127-nettow-20ml/20180129-IceEdge-sample0127-nettow-20ml_000076_0011.tif is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "for i, ifolder in enumerate(glob.glob('test-data/*/')):\n",
    "    outdir = 'test-data/processed-data/individual-tifs/'+ifolder.split('/')[-2]\n",
    "    if os.path.exists(outdir):\n",
    "        pass\n",
    "    else:\n",
    "        print(ifolder)\n",
    "        batch_cut_images(directory=ifolder, outdirectory= 'test-data/processed-data/individual-tifs/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing of individual tifs to find edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbg_to_bw(I, yen=True):\n",
    "    '''\n",
    "    rgb_to_bw: converts image to bw based on chosen threshold; automatically use yen. \n",
    "\n",
    "    I = image handle (intialized with scikit image package using io.imread)\n",
    "    yen = T/F use yen method for threshold or otsu (bool)\n",
    "    '''\n",
    "    # convert to gray\n",
    "    Ig = color.rgb2gray(I)\n",
    "    \n",
    "    #convert to binary\n",
    "    if yen:\n",
    "        thresh = filters.threshold_yen(Ig)\n",
    "    else:\n",
    "        thresh = filters.threshold_otsu(Ig)\n",
    "    Ibw = (Ig <= thresh)\n",
    "    Ibw = Ibw.astype(int)\n",
    "    \n",
    "    return(Ibw)\n",
    "\n",
    "def edge_detect(Ibw, sobel=True):\n",
    "    '''\n",
    "    edge_detect: run edge detection on a provided binary image\n",
    "\n",
    "    Ibw = image handle for binary image\n",
    "    sobel = TRUE = use sobel method for edge detection; FALSE = use canny method (bool)\n",
    "    '''\n",
    "    \n",
    "    if sobel:\n",
    "        edges = filters.sobel(Ibw)\n",
    "    else:\n",
    "        edges = feature.canny(Ibw)\n",
    "        \n",
    "    return edges\n",
    "\n",
    "def dilation(edges, selem_size=8):\n",
    "    '''\n",
    "    dilation: run dilation on set of edges with a specified selem_size for a disk\n",
    "    \n",
    "    edges = image handle for edges file\n",
    "    selem_size = size of selem to use for the dilation (int)\n",
    "    '''\n",
    "    \n",
    "    selem = morphology.disk(selem_size)\n",
    "    dilated = morphology.binary_dilation(edges, selem)\n",
    "    return dilated\n",
    "\n",
    "def fill_erode_close(dilated, selem_size=8):\n",
    "    '''\n",
    "    fill_eroted_close: runclosing and reconstruction on provided binary image with selected selem_siz\n",
    "    \n",
    "    dilated = image handle for dilated or processed binary image file\n",
    "    selem_size = size of selem to use for the dilation (int)\n",
    "    '''\n",
    "    # fill the edges\n",
    "    seed = np.copy(dilated)\n",
    "    seed[1:-1, 1:-1] = dilated.max()\n",
    "    mask = dilated\n",
    "    filled = morphology.reconstruction(seed, mask, method='erosion')\n",
    "    \n",
    "    # close small holes\n",
    "    selem = morphology.disk(selem_size)\n",
    "    close_filled = morphology.binary_closing(filled, selem)\n",
    "    close_filled = close_filled.astype('int')\n",
    "\n",
    "    return close_filled\n",
    "\n",
    "def manual_fill_holes(close_filled):\n",
    "    '''\n",
    "    manual_fill_holes: manually identify small holes within the image region and draw a circle \n",
    "    around them equal to the diameter of the longest axis or equivalent diameter\n",
    "    \n",
    "    close_filled = image handle for binary image with holes to be filled. Holes = 0s. \n",
    "    '''\n",
    "    \n",
    "    # label the inverse of the close_filled object\n",
    "    close_filled_label = measure.label(1-close_filled, connectivity=2)\n",
    "    shape = np.shape(close_filled_label)\n",
    "    \n",
    "    #get regional properties\n",
    "    rp_cfl= measure.regionprops(close_filled_label)\n",
    "    a=[]\n",
    "    a_lab=[]\n",
    "    for i in rp_cfl:\n",
    "        a.append(i.area)\n",
    "        a_lab.append(i.label)\n",
    "    asum=sum(a)\n",
    "    a_lab_sorted = [x for _,x in sorted(zip(a,a_lab), reverse=True)]\n",
    "    rp_cfl.pop(a_lab_sorted[0]-1)\n",
    "    # cut based on size instead of order?\n",
    "    # for aa in a:\n",
    "    #     if aa > 0.2 * asum:\n",
    "    #         print(aa)\n",
    "    \n",
    "    # draw circles over remaining holes\n",
    "    base = close_filled.copy()\n",
    "    \n",
    "    for r in rp_cfl:\n",
    "        radius =  r.major_axis_length/2\n",
    "        center = r.centroid\n",
    "        \n",
    "        # make sure circle doesn't exceed the size of the image\n",
    "        if np.any((np.max(radius) + center> shape[0])|(np.max(radius) + center> shape[1])):\n",
    "            radius =  r.equivalent_diameter/2\n",
    "        if np.any((np.max(radius) + center> shape[0])|(np.max(radius) + center> shape[1])):\n",
    "            pass\n",
    "        else:\n",
    "            rr, cc = draw.circle(center[0], center[1], radius)\n",
    "            base[rr, cc] = 1\n",
    "            \n",
    "    return base\n",
    "\n",
    "def get_final_edge(Ifinal):\n",
    "    '''\n",
    "    get_final_edge: take in the final binary image and detect the edges. return bool of edges. \n",
    "    \n",
    "    Ifinal = image handle for final binary file of total region\n",
    "    '''\n",
    "    edge = edge_detect(Ifinal)\n",
    "    edge[edge==0] = np.nan\n",
    "    edge[edge>0]=1\n",
    "    \n",
    "    return(edge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch process individual tif files to identify edges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identify_edges(I, plot = False):\n",
    "    '''\n",
    "    identify_edges: pipeline to run analysis on provided image handle \n",
    "    \n",
    "    I = image handle for rgb input tif file\n",
    "    plot = TRUE = plot all the figures and save as edge file. Adds a lot of time. \n",
    "    '''\n",
    "    Ibw = rbg_to_bw(I)\n",
    "    Iedge = edge_detect(Ibw)\n",
    "    Idilation = dilation(Iedge)\n",
    "    Ifilled = fill_erode_close(Idilation)\n",
    "    Imanfill = manual_fill_holes(Ifilled)\n",
    "    Ifinal = fill_erode_close(Imanfill)\n",
    "    Iedge_final = get_final_edge(Ifinal)\n",
    "    \n",
    "    if plot == True:\n",
    "        fig, ax = plt.subplots(1,4, figsize = [12,12])\n",
    "        ax[0].imshow(Ibw, cmap=plt.cm.gray)\n",
    "        ax[1].imshow(Idilation, cmap=plt.cm.gray)\n",
    "        ax[2].imshow(Ifinal, cmap=plt.cm.gray)\n",
    "        ax[3].imshow(I)\n",
    "        ax[3].imshow(Iedge_final, cmap=plt.cm.hs)\n",
    "        for a in ax:\n",
    "            a.set_xticklabels('')\n",
    "            a.set_yticklabels('')\n",
    "\n",
    "        return(Iedge_final, Ifinal, fig, ax)\n",
    "    \n",
    "    else: \n",
    "        return(Iedge_final, Ifinal, Ibw)\n",
    "    \n",
    "    \n",
    "def batch_process_images(wd, ftype = '*tif', makeplots = False):\n",
    "    '''\n",
    "    batch_process_images: batch process directories of files. Find tif files nad process them. \n",
    "    \n",
    "    I = image handle for rgb input tif file\n",
    "    plot = TRUE = plot all the figures and save as edge file. Adds a lot of time. \n",
    "    \n",
    "    returns a dictionary that is indexed by the file name and contains all the different images. \n",
    "    '''\n",
    "    c=0\n",
    "    Idict = {}\n",
    "    for ifile in glob.glob(wd + ftype):\n",
    "        name = ifile.split('/')[-1] \n",
    "        # read in image\n",
    "        try:\n",
    "            I = io.imread(ifile)\n",
    "        except: \n",
    "            print('Could not read ' + ifile)\n",
    "            continue\n",
    "        # if you want to save plots\n",
    "        if makeplots == True:\n",
    "            (Iedge_final, Ifinal, fig, ax) = identify_edges(I, plot = makeplots)\n",
    "            outfile = ifile[:-4]+'_edge.tif'\n",
    "            fig.savefig(outfile)\n",
    "            plt.close()\n",
    "        else:\n",
    "            (Iedge_final, Ifinal, Ibw) = identify_edges(I, plot = makeplots)\n",
    "\n",
    "        #output dictionary: rgb = rgb image, edge = final edge file, \n",
    "        #binary = final binary of larger regions, Ibw = binary of original image\n",
    "        Idict[name]={'rbg':I, 'edge':Iedge_final, 'binary': Ifinal, 'Ibw': Ibw}\n",
    "\n",
    "#         if c ==5:\n",
    "#             break\n",
    "#         if c%100 ==0:\n",
    "#             print(c)\n",
    "        c+=1\n",
    "\n",
    "    return Idict\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process experimental data in `data/processed-data/indvidual-tifs/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180129-IceEdge-sample0127-0m-500ml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from int64 to float64\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:121: RuntimeWarning: invalid value encountered in greater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180129-IceEdge-sample0127-10m-200ml\n",
      "20180129-IceEdge-sample0127-10m-50ml\n",
      "20180129-IceEdge-sample0127-nettow-20ml\n"
     ]
    }
   ],
   "source": [
    "# masterDict = {}\n",
    "\n",
    "pickleDir = 'test-data/processed-data/pickle-dicts/'\n",
    "if not os.path.exists(pickleDir):\n",
    "    os.makedirs(pickleDir)\n",
    "\n",
    "for i, folder in enumerate(glob.glob('test-data/processed-data/individual-tifs/*/')):\n",
    "    outName = (folder.split('/')[-2])\n",
    "    pout = pickleDir + outName + '.pickle'\n",
    "    print(outName)\n",
    "    if os.path.exists(pout):\n",
    "        pass\n",
    "    else:\n",
    "        Idict = batch_process_images(folder, makeplots = False)\n",
    "#         masterDict[outName]=Idict\n",
    "        outPickle = open(pickleDir + outName+'.pickle', 'wb')\n",
    "        cpk.dump(Idict, outPickle)\n",
    "        outPickle.close()\n",
    "#         if i == 1:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/test-set/notPhaeo/\n",
      "data/test-set/Phaeo/\n",
      "data/training-set/notPhaeo/\n",
      "data/training-set/Phaeo/\n"
     ]
    }
   ],
   "source": [
    "for ff in ['test-data/test-set/', 'test-data/training-set/']:\n",
    "    for i, folder in enumerate(glob.glob(ff+'*/')):\n",
    "        print(folder)\n",
    "        outName = folder.split('/')[-2]\n",
    "        outName = outName + folder.split('/')[-3]\n",
    "        pout = pickleDir + outName + '.pickle'\n",
    "        if os.path.exists(pout):\n",
    "            pass\n",
    "        else:\n",
    "            Idict = batch_process_images(folder, makeplots = False)\n",
    "#             training_dict[outName]=Idict\n",
    "            outPickle = open(pickleDir + outName+'.pickle', 'wb')\n",
    "            cpk.dump(Idict, outPickle)\n",
    "#     if i == 1:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculation of regional properties for each individual tif image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_region(rbg, Ibw, Ifinal):\n",
    "    '''\n",
    "    get_largest_region: gets the region with the largest area identified in Ifinal \n",
    "    \n",
    "    rbg = image handle for rgb input tif file\n",
    "    Ibw = image handle for raw binary image\n",
    "    Ifinal = image handle for the dilated binary image (final)\n",
    "    \n",
    "    Returns  binary image (Ibw_regional) and color image (rbg_regional) masked by the largest region (max_binary)\n",
    "    '''\n",
    "    \n",
    "    # label the binary image\n",
    "    lab_bin = measure.label(Ifinal, connectivity = 2)\n",
    "    rp = measure.regionprops(lab_bin)\n",
    "    \n",
    "    # get the label with the max area\n",
    "    areas = [r.area for r in rp]\n",
    "    labs = [r.label for r in rp]\n",
    "    Ibw_regional = Ibw.copy()\n",
    "    \n",
    "    # get the largest area\n",
    "    if len(areas)>0:\n",
    "        max_lab = labs[areas.index(max(areas))]\n",
    "        # get bool for the max area and the not max area\n",
    "        not_max_binary = lab_bin != max_lab\n",
    "        max_binary = lab_bin == max_lab\n",
    "        # set things outside of largest area to 0 in binary and color image\n",
    "        Ibw_regional[not_max_binary] = 0\n",
    "        rbg_regional = np.where(max_binary[...,None], rbg, 0)\n",
    "    else: \n",
    "        # if no regions present\n",
    "        Ibw_regional = -9999999\n",
    "        rbg_regional = -9999999\n",
    "        max_binary = -9999999\n",
    "        pass\n",
    "    \n",
    "    return Ibw_regional, rbg_regional, max_binary\n",
    "\n",
    "\n",
    "def number_sub_areas(Ibw_regional):\n",
    "    '''\n",
    "    number_sub_areas: gets the number of subregions in the region with the largest area\n",
    "    \n",
    "    Ibw_regional = image handle binary original image masked by the largest region\n",
    "    \n",
    "    Returns number of sub regions (int)\n",
    "    '''\n",
    "\n",
    "    # calculate the number of distinct sub areas within the blob of the largest region\n",
    "    Ibw_reg_lab = measure.label(Ibw_regional)\n",
    "    rp = measure.regionprops(Ibw_reg_lab)\n",
    "    num_regions = len(rp)\n",
    "    return num_regions\n",
    "\n",
    "def proportion_occupied(Ibw_regional, max_binary):\n",
    "    '''\n",
    "    proportion_occupied: calculates the proprotion of the largest region that is \n",
    "    occupied by sub regions\n",
    "    \n",
    "    Ibw_regional = image handle binary original image masked by the largest region\n",
    "    max_binary = image handle for binary image of the largest region\n",
    "    \n",
    "    Returns proprotion of occupied area (float) \n",
    "    '''\n",
    "\n",
    "    # calualte the proportion of the largest region occupied by subregions (i.e. the density of the subregions)\n",
    "    reginonal_area = np.sum(Ibw_regional)\n",
    "    max_area = np.sum(max_binary)\n",
    "    prop_oc = reginonal_area/ float(max_area)\n",
    "    return prop_oc \n",
    "    \n",
    "    \n",
    "def mean_size_area(Ibw_regional, cutoff = 50):\n",
    "    '''\n",
    "    mean_size_area: calculates the mean and std area of the subareas within the largest region \n",
    "    above a specified pixel size cutoff value \n",
    "    \n",
    "    Ibw_regional = image handle binary original image masked by the largest region\n",
    "    cutoff = number of pixels required for inclusion of a sub area in the analysis (int)\n",
    "    \n",
    "    Returns area distribution (areas), mean area (a_mean), and standard dev (a_std)\n",
    "    '''\n",
    "\n",
    "    # calculate the mean area for the sub regions of the largest region with a specified size cut off value\n",
    "    Ibw_reg_lab = measure.label(Ibw_regional)\n",
    "    rp = measure.regionprops(Ibw_reg_lab)\n",
    "    areas = []\n",
    "    for r in rp: \n",
    "        a = r.area\n",
    "        lab = r.label\n",
    "        if a > cutoff:\n",
    "            areas.append(a)\n",
    "    a_mean  = np.mean(areas)\n",
    "    a_std = np.std(areas)\n",
    "    \n",
    "    return areas, a_mean, a_std\n",
    "\n",
    "def get_sub_region_color(rbg_regional):\n",
    "    '''\n",
    "    get_sub_region_color: returns the mean and std color intensity for the subregions \n",
    "    in the rgb_regional image across R, G, and B. \n",
    "    \n",
    "    rbg_regional = image handle rgb original image masked by the largest region\n",
    "    \n",
    "    Returns dictionary containing the mean, stdev, median, color_entropy for \n",
    "    each of the color channels of occupied areas as well as the ratios between colors \n",
    "    '''\n",
    "    \n",
    "    # loop over color channels\n",
    "    rgb_dict ={}\n",
    "    ratio_dict ={}\n",
    "    for i, cc in enumerate(['red', 'green', 'blue']):\n",
    "        color_chan = pd.DataFrame(rbg_regional[:, :, i])\n",
    "        color_chan[color_chan == 0] = np.nan\n",
    "        c_mean = color_chan.mean().mean()\n",
    "        c_std = color_chan.std().std()\n",
    "        c_median = color_chan.median().median()\n",
    "        a_chan=np.array(color_chan.fillna(0))\n",
    "        shan_ent = measure.shannon_entropy(a_chan)\n",
    "        in_dict = {'color_mean': c_mean, 'color_std': c_std, \n",
    "                   'color_median': c_median, 'color_shannon_entropy': shan_ent}\n",
    "        rgb_dict[cc]=in_dict\n",
    "    ratio_dict['ratio_r_b']= rgb_dict['red']['color_mean']/rgb_dict['blue']['color_mean']\n",
    "    ratio_dict['ratio_r_g']= rgb_dict['red']['color_mean']/rgb_dict['green']['color_mean']\n",
    "    ratio_dict['ratio_b_g']= rgb_dict['blue']['color_mean']/rgb_dict['green']['color_mean']\n",
    "\n",
    "    return rgb_dict, ratio_dict\n",
    "\n",
    "\n",
    "\n",
    "def regionProps(Idict):\n",
    "    '''\n",
    "    regionProps: the built in region props (listed below) for the largest region \n",
    "    \n",
    "    Idict = dictionary containing image information\n",
    "    \n",
    "    Adds to the input dictionary Idict and returns a pandas df with the property values\n",
    "    '''\n",
    "    props_included = ['area','bbox_area','convex_area','eccentricity','equivalent_diameter',\n",
    "                     'extent','filled_area','major_axis_length','minor_axis_length', \n",
    "                      'orientation', 'perimeter','solidity','shannon_entropy']\n",
    "    out_pd = pd.DataFrame(columns=props_included)\n",
    "\n",
    "    for i,I in enumerate(Idict.keys()):\n",
    "        # load in data\n",
    "        # the largest area to be considered\n",
    "        Ifinal = Idict[I]['binary']\n",
    "        mask = Ifinal.astype('bool')\n",
    "        # color image\n",
    "        rbg = Idict[I]['rbg']\n",
    "        # bw rendering of the color image\n",
    "        Ibw = Idict[I]['Ibw']\n",
    "\n",
    "        # get the regional Ibw region, rbg region, and max_binary image of the largest region\n",
    "        Ibw_regional, rbg_regional, max_binary = get_largest_region(rbg, Ibw, Ifinal)\n",
    "        if np.any(Ibw_regional ==  -9999999):\n",
    "            pass\n",
    "        else:\n",
    "            max_binary = max_binary.astype(int)\n",
    "        \n",
    "            # calcualte region props for the max binary region\n",
    "            rp = measure.regionprops(max_binary)\n",
    "            r = rp[0]\n",
    "            for rr in r:\n",
    "                if rr in props_included:\n",
    "                    # add to df\n",
    "                    out_pd.loc[I, rr] = r[rr]\n",
    "         \n",
    "            Idict[I]['Ibw_regional'] = Ibw_regional\n",
    "            Idict[I]['rbg_regional'] = rbg_regional\n",
    "            Idict[I]['max_binary'] = max_binary\n",
    "\n",
    "            out_pd.loc[I, 'shannon_entropy'] = measure.shannon_entropy(rbg_regional)\n",
    "                \n",
    "    return out_pd, Idict\n",
    "\n",
    "def user_defined_properties(Idict, out_pd):\n",
    "    '''\n",
    "    user_defined_properties: returns user specified regional properites to pandas dictionary\n",
    "    \n",
    "    Idict = dictionary containing image information\n",
    "    out_pd = pandas df out put by regionProps function\n",
    "    \n",
    "    Returns region props pandas dataframe\n",
    "    '''\n",
    "    for i,I in enumerate(out_pd.index):\n",
    "\n",
    "        Ibw_regional = Idict[I]['Ibw_regional']\n",
    "        rbg_regional = Idict[I]['rbg_regional'] \n",
    "        max_binary = Idict[I]['max_binary']\n",
    "\n",
    "        num_subregions = number_sub_areas(Ibw_regional)\n",
    "        prop_oc = proportion_occupied(Ibw_regional, max_binary)\n",
    "        areas, a_mean, a_std = mean_size_area(Ibw_regional)\n",
    "        rgb_dict, ratio_dict = get_sub_region_color(rbg_regional)\n",
    "        \n",
    "        out_pd.loc[I, 'num_subregions'] = num_subregions\n",
    "        out_pd.loc[I, 'proportion_occupied'] = prop_oc\n",
    "        out_pd.loc[I, 'subregion_mean_area'] = a_mean\n",
    "        out_pd.loc[I, 'subregion_std_area'] = a_std\n",
    "        \n",
    "        for key in rgb_dict.keys():\n",
    "            for subkey in rgb_dict[key].keys():\n",
    "                out_pd.loc[I, key+'_'+subkey] = rgb_dict[key][subkey]\n",
    "        for key in ratio_dict.keys():\n",
    "            out_pd.loc[I, key] = ratio_dict[key]\n",
    "            \n",
    "    return out_pd\n",
    "  \n",
    "def properties_to_csv(Idict, filename): \n",
    "    out_pd, Idict = regionProps(Idict)\n",
    "    out_pd = user_defined_properties(Idict, out_pd)\n",
    "    out_pd.to_csv(filename)\n",
    "    return(Idict, out_pd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed-data/pickle-dicts/20180127-PhaeoEx-AB12-1-T7-200ml.pickle\n",
      "data/processed-data/pickle-dicts/20180127-PhaeoEx-AB12-2-T7-200ml.pickle\n",
      "data/processed-data/pickle-dicts/20180127-PhaeoEx-AB12-3-T7-200ml.pickle\n",
      "data/processed-data/pickle-dicts/20180127-PhaeoEx-Anti-1-T7-200ml.pickle\n",
      "data/processed-data/pickle-dicts/20180129-IceEdge-sample0127-0m-500ml.pickle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2957: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/Users/halexand/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/processed-data/pickle-dicts/20180129-IceEdge-sample0127-10m-200ml.pickle\n",
      "data/processed-data/pickle-dicts/20180129-IceEdge-sample0127-10m-50ml.pickle\n",
      "data/processed-data/pickle-dicts/20180129-IceEdge-sample0127-nettow-20ml.pickle\n"
     ]
    }
   ],
   "source": [
    "csvdir = 'test-data/processed-data/region_props_csv/'\n",
    "rp_dict = {}\n",
    "if not os.path.exists(csvdir):\n",
    "    os.mkdir(csvdir)\n",
    "\n",
    "for pfile in glob.glob('test-data/processed-data/pickle-dicts/*pickle'):\n",
    "    print(pfile)\n",
    "    name = pfile.split('/')[-1].split('.')[0]\n",
    "    csvfile = name +'.csv'\n",
    "    if os.path.exists(csvdir+csvfile):\n",
    "        pass\n",
    "    else:\n",
    "        Idict = cpk.load(open(pfile, 'rb'))\n",
    "        Idict, outpd = properties_to_csv(Idict, csvdir + csvfile)\n",
    "        cpk.dump(Idict, open(pfile+'2', 'wb'))\n",
    "        rp_dict[name] = outpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
